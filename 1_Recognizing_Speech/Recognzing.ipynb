{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('x_digits.npy')\n",
    "Y = np.load('y_digits.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129, 71), (35631,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 35 thousand 'pictures' (observations) representing numbers from 0 to 9. Each number has 129 rows with 71 columns. (maybe, maybe not, check again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape([-1, 129, 71, 1])\n",
    "X_test = X_test.reshape([-1, 129, 71, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data in train and test sets as we will use the built-in split from tensorflow when training the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 71, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 1:\n",
    "We start of with a small neural network, keeping the size of the feature maps relavtively small. As advised we use the ReLu activation function. The size of the feature map is 3 x 3. We also use EarlyStopping callback and Learning Rate callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - accuracy: 0.1400 - loss: 3.1947 - val_accuracy: 0.2510 - val_loss: 1.9091 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.3351 - loss: 1.7517 - val_accuracy: 0.6904 - val_loss: 0.9012 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7465 - loss: 0.7481 - val_accuracy: 0.8223 - val_loss: 0.5392 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.8577 - loss: 0.4218 - val_accuracy: 0.8720 - val_loss: 0.3843 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9089 - loss: 0.2721 - val_accuracy: 0.8995 - val_loss: 0.3058 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9381 - loss: 0.1886 - val_accuracy: 0.9035 - val_loss: 0.2971 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9531 - loss: 0.1450 - val_accuracy: 0.9128 - val_loss: 0.2974 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9622 - loss: 0.1122 - val_accuracy: 0.9123 - val_loss: 0.3068 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9763 - loss: 0.0685 - val_accuracy: 0.9205 - val_loss: 0.2946 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9915 - loss: 0.0335 - val_accuracy: 0.9263 - val_loss: 0.2940 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9931 - loss: 0.0273 - val_accuracy: 0.9204 - val_loss: 0.3396 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9933 - loss: 0.0242 - val_accuracy: 0.9207 - val_loss: 0.3398 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9960 - loss: 0.0165 - val_accuracy: 0.9248 - val_loss: 0.3463 - learning_rate: 2.5000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9983 - loss: 0.0073 - val_accuracy: 0.9235 - val_loss: 0.3635 - learning_rate: 2.5000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9997 - loss: 0.0042 - val_accuracy: 0.9246 - val_loss: 0.3788 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(X_train[0].shape))\n",
    "model.add(tf.keras.layers.Conv2D(8, (3,3), activation = \"relu\", kernel_initializer = \"he_normal\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(16, (3,3), activation = \"relu\", kernel_initializer = \"he_normal\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation = \"relu\", kernel_initializer = \"he_normal\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation = \"relu\", kernel_initializer = \"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "EarlyStoppingCB = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 5, restore_best_weights = \"True\")\n",
    "LearningRateCB = tf.keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience = 2)\n",
    "\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate = 0.001, weight_decay = 0.002)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "history = model.fit(X_train, Y_train, epochs = 30, validation_split=0.2, callbacks = [EarlyStoppingCB, LearningRateCB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[3.4356715e-17, 1.2530337e-07, 2.4519258e-12, 1.8482159e-10,\n",
       "         3.2657042e-07, 9.9960572e-01, 5.1621953e-07, 3.9195173e-04,\n",
       "         1.2881912e-06, 7.9463618e-08]], dtype=float32),\n",
       " 5.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_example = X_test[0]  # Example, take the first sample from the test set\n",
    "single_example = single_example.reshape(129, 71, 1)  # Reshape to (129, 71, 1)\n",
    "\n",
    "# Expand dimensions to make it a batch of size 1 (shape becomes (1, 129, 71, 1))\n",
    "single_example = np.expand_dims(single_example, axis=0)\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(single_example)\n",
    "\n",
    "# Print the prediction (depending on your output layer, this could be probabilities or class labels)\n",
    "prediction, Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArEAAAIjCAYAAAAUdENlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2sklEQVR4nO3dfZzM9f7/8efYtbNrd2fI5W4GWddLnIjbIkWyuUp1KuSrpXS5ulo5J6cLVKzUUedb2kpFJ+SkEzpFQugrnNZFRa5yFRWK2Flkl93374+O+TV2xY7d/cz7eNxvt7ndznzmPTOv3c9XPfp83zNcxhgjAAAAwCIVnB4AAAAAKCkiFgAAANYhYgEAAGAdIhYAAADWIWIBAABgHSIWAAAA1iFiAQAAYB0iFgAAANYhYgEAAGAdIhZA2KpXr54GDRrk9BiOcblcGjp0aKm93pQpU+RyubRq1aozrr3iiit0xRVXBO7v3LlTLpdLU6ZMCRwbNWqUXC5Xid57586dJZwaAIpHxAIod9u2bdOdd96p+vXrKzo6Wh6PRx06dNDf/vY3/fLLL06P97tOxtjJW3R0tBo1aqShQ4dq3759To/nuLFjx2r27NlOjwHgPBDp9AAAzi8ffvihbrzxRrndbt1yyy1q3ry58vPztWzZMg0fPlxff/21Xn31VafHPKMnnnhCF110kY4dO6Zly5YpKytLc+fO1fr161WpUiWnxztnH3/88RnXPProo3r44YeDjo0dO1Y33HCDrr322qDjAwcOVL9+/eR2u0tzTADnMSIWQLnZsWOH+vXrp7p16+qTTz5RQkJC4LH09HRt3bpVH374oYMTnr3u3burTZs2kqQhQ4aoatWqmjBhgubMmaP+/fsX+5wjR44oNja2PMcMWVRU1BnXREZGKjLy7P41EhERoYiIiHMdCwAC2E4AoNyMHz9ehw8f1uuvvx4UsCc1aNBA999//2mf//PPP+uhhx5SixYtFBcXJ4/Ho+7du+vLL78ssvaFF15QcnKyKlWqpCpVqqhNmzaaPn164PHc3Fw98MADqlevntxut2rUqKGrrrpKa9asCeln69Kli6RfQ12SBg0apLi4OG3btk09evRQfHy8BgwYIOnXmB02bJh8Pp/cbrcaN26sZ599VsaYYl972rRpaty4saKjo9W6dWt9+umnQY9/++23uueee9S4cWPFxMSoatWquvHGG0+7//To0aO68847VbVqVXk8Ht1yyy06ePBg0JpT98QW59Q9sS6XS0eOHNGbb74Z2G5xck/z6fbEzps3T5dddpliY2MVHx+vnj176uuvvw5as3fvXg0ePFi1a9eW2+1WQkKC+vTpw/5a4DzHlVgA5eZf//qX6tevr/bt24f0/O3bt2v27Nm68cYbddFFF2nfvn165ZVXdPnll2vDhg1KTEyUJE2aNEn33XefbrjhBt1///06duyYvvrqK/373//WzTffLEm666679O6772ro0KFq1qyZDhw4oGXLlmnjxo265JJLSjzbtm3bJElVq1YNHDtx4oRSU1PVsWNHPfvss6pUqZKMMbrmmmu0ePFi3XbbbWrVqpXmz5+v4cOH6/vvv9dzzz0X9LpLly7VP/7xD913331yu9166aWXdPXVV+vzzz9X8+bNJUnZ2dlavny5+vXrp9q1a2vnzp3KysrSFVdcoQ0bNhTZ3jB06FBVrlxZo0aN0ubNm5WVlaVvv/1WS5YsOesPahXnrbfe0pAhQ9S2bVvdcccdkqSkpKTfXZ+WlqbU1FQ9/fTTOnr0qLKystSxY0etXbtW9erVkyT98Y9/1Ndff617771X9erV048//qgFCxZo165dgTUAzkMGAMpBTk6OkWT69Olz1s+pW7euSUtLC9w/duyYKSgoCFqzY8cO43a7zRNPPBE41qdPH5OcnPy7r+31ek16evpZz3LS5MmTjSSzcOFC89NPP5ndu3ebGTNmmKpVq5qYmBjz3XffGWOMSUtLM5LMww8/HPT82bNnG0nmqaeeCjp+ww03GJfLZbZu3Ro4JslIMqtWrQoc+/bbb010dLS57rrrAseOHj1aZM4VK1YYSebvf/97kdlbt25t8vPzA8fHjx9vJJk5c+YEjl1++eXm8ssvD9zfsWOHkWQmT54cODZy5Ehz6r9GYmNjg87Zqe+9Y8cOY4wxubm5pnLlyub2228PWrd3717j9XoDxw8ePGgkmWeeeabIawI4v7GdAEC58Pv9kqT4+PiQX8PtdqtChV//sVVQUKADBw4oLi5OjRs3DtoGULlyZX333XfKzs4+7WtVrlxZ//73v/XDDz+ENEvXrl1VvXp1+Xw+9evXT3FxcZo1a5YuvPDCoHV333130P25c+cqIiJC9913X9DxYcOGyRijefPmBR1PSUlR69atA/fr1KmjPn36aP78+SooKJAkxcTEBB4/fvy4Dhw4oAYNGqhy5crFbo+44447VLFixaAZIyMjNXfu3BL+FkK3YMECHTp0SP3799f+/fsDt4iICLVr106LFy+W9OvPFhUVpSVLlhTZ8gDg/EbEAigXHo9H0q97UUNVWFio5557Tg0bNpTb7Va1atVUvXp1ffXVV8rJyQms+/Of/6y4uDi1bdtWDRs2VHp6uj777LOg1xo/frzWr18vn8+ntm3batSoUdq+fftZzzJx4kQtWLBAixcv1oYNG7R9+3alpqYGrYmMjFTt2rWDjn377bdKTEwsEvNNmzYNPP5bDRs2LPLejRo10tGjR/XTTz9Jkn755Rc9/vjjgT22J38vhw4dCvq9nO414+LilJCQUK57TL/55htJv+4lrl69etDt448/1o8//ijp1/9wefrppzVv3jzVrFlTnTp10vjx47V3795ymxVAeCJiAZQLj8ejxMRErV+/PuTXGDt2rDIyMtSpUydNnTpV8+fP14IFC5ScnKzCwsLAuqZNm2rz5s2aMWOGOnbsqH/+85/q2LGjRo4cGVhz0003afv27XrhhReUmJioZ555RsnJyUWuhJ5O27Zt1bVrV11xxRVq2rRp4Arxb/32ynFZuvfeezVmzBjddNNNeuedd/Txxx9rwYIFqlq1atDvJZycnOutt97SggULitzmzJkTWPvAAw9oy5YtyszMVHR0tB577DE1bdpUa9eudWp8AGGAD3YBKDe9evXSq6++qhUrViglJaXEz3/33XfVuXNnvf7660HHDx06pGrVqgUdi42NVd++fdW3b1/l5+fr+uuv15gxYzRixAhFR0dLkhISEnTPPffonnvu0Y8//qhLLrlEY8aMUffu3UP/Ic+gbt26WrhwoXJzc4Ouxm7atCnw+G+dvGL5W1u2bFGlSpVUvXp1Sb/+XtLS0vTXv/41sObYsWM6dOhQsTN888036ty5c+D+4cOHtWfPHvXo0SPkn+uks/1g2MkPfNWoUUNdu3Y9q/XDhg3TsGHD9M0336hVq1b661//qqlTp57TvADsxZVYAOXmT3/6k2JjYzVkyJBi/3arbdu26W9/+9tpnx8REVHka6hmzpyp77//PujYgQMHgu5HRUWpWbNmMsbo+PHjKigoKPL/Zq9Ro4YSExOVl5dX0h+rRHr06KGCggK9+OKLQcefe+45uVyuIgG9YsWKoH2tu3fv1pw5c9StW7fA964W93t54YUXAntmT/Xqq6/q+PHjgftZWVk6ceJEqcR7bGzsaeP5t1JTU+XxeDR27NigWU46uVXi6NGjOnbsWNBjSUlJio+PL/NzBSC8cSUWQLlJSkrS9OnT1bdvXzVt2jTob+xavny5Zs6cGfhe0eL06tVLTzzxhAYPHqz27dtr3bp1mjZtmurXrx+0rlu3bqpVq5Y6dOigmjVrauPGjXrxxRfVs2dPxcfH69ChQ6pdu7ZuuOEGtWzZUnFxcVq4cKGys7ODrmaWhd69e6tz58565JFHtHPnTrVs2VIff/yx5syZowceeKDIV1I1b95cqampQV+xJUmjR48O+r289dZb8nq9atasmVasWKGFCxcGfd3Xb+Xn5+vKK6/UTTfdpM2bN+ull15Sx44ddc0115zzz9e6dWstXLhQEyZMUGJioi666CK1a9euyDqPx6OsrCwNHDhQl1xyifr166fq1atr165d+vDDD9WhQwe9+OKL2rJlS2DWZs2aKTIyUrNmzdK+ffvUr1+/c54XgMWc/XIEAOejLVu2mNtvv93Uq1fPREVFmfj4eNOhQwfzwgsvmGPHjgXWFfcVW8OGDTMJCQkmJibGdOjQwaxYsaLI10G98sorplOnTqZq1arG7XabpKQkM3z4cJOTk2OMMSYvL88MHz7ctGzZ0sTHx5vY2FjTsmVL89JLL51x9pNfFZWdnf2769LS0kxsbGyxj+Xm5poHH3zQJCYmmooVK5qGDRuaZ555xhQWFgatk2TS09PN1KlTTcOGDY3b7TZ/+MMfzOLFi4PWHTx40AwePNhUq1bNxMXFmdTUVLNp06Yiv7+Tsy9dutTccccdpkqVKiYuLs4MGDDAHDhwIOg1Q/2KrU2bNplOnTqZmJgYIynw/qd+xdZJixcvNqmpqcbr9Zro6GiTlJRkBg0aFPhasf3795v09HTTpEkTExsba7xer2nXrp155513TvObB3C+cBlzmr8iBgAAAAhT7IkFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYx+q/7KCwsFA//PCD4uPjz/qvOgQAAED5McYoNzdXiYmJqlCh9K6fWh2xP/zwg3w+n9NjAAAA4Ax2796t2rVrl9rrWR2x8fHxkn79pXg8HoenAQAAwKn8fr98Pl+g20qL1RF7cguBx+MhYgEAAMJYaW/95INdAAAAsA4RCwAAAOsQsQAAALAOEQsAAADrELEAAACwDhELAAAA6xCxAAAAsA4RCwAAAOsQsQAAALAOEQsAAADrELEAAACwDhELAAAA6xCxAAAAsA4RCwAAAOsQsQAAALAOEQsAAADrELEAAACwDhELAAAA6xCxAAAAsA4RCwAAAOsQsQAAALAOEQsAAADrELEAAACwDhELAAAA6xCxAAAAsA4RCwAAAOsQsQAAALAOEQsAAADrELEAAACwDhELAAAA6xCxAAAAsI6jEZubm6sHHnhAdevWVUxMjNq3b6/s7GwnRwIAAIAFHI3YIUOGaMGCBXrrrbe0bt06devWTV27dtX333/v5FgAAAAIcy5jjHHijX/55RfFx8drzpw56tmzZ+B469at1b17dz311FNnfA2/3y+v16ucnBx5PJ6yHBcAAAAhKKteiyy1VyqhEydOqKCgQNHR0UHHY2JitGzZsmKfk5eXp7y8vMB9v99fpjMCAAAgPDm2nSA+Pl4pKSl68skn9cMPP6igoEBTp07VihUrtGfPnmKfk5mZKa/XG7j5fL5ynhoAAADhwLHtBJK0bds23Xrrrfr0008VERGhSy65RI0aNdLq1au1cePGIuuLuxLr8/nYTgAAABCm/uu2E0hSUlKSli5dqiNHjsjv9yshIUF9+/ZV/fr1i13vdrvldrvLeUoAAACEm7D4ntjY2FglJCTo4MGDmj9/vvr06eP0SAAAAAhjjl6JnT9/vowxaty4sbZu3arhw4erSZMmGjx4sJNjAQAAIMw5eiU2JydH6enpatKkiW655RZ17NhR8+fPV8WKFZ0cCwAAAGHO0Q92nSu+JxYAACC8lVWvhcWeWAAAAKAkiFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYx9GILSgo0GOPPaaLLrpIMTExSkpK0pNPPiljjJNjAQAAIMxFOvnmTz/9tLKysvTmm28qOTlZq1at0uDBg+X1enXfffc5ORoAAADCmKMRu3z5cvXp00c9e/aUJNWrV09vv/22Pv/8cyfHAgAAQJhzdDtB+/bttWjRIm3ZskWS9OWXX2rZsmXq3r17sevz8vLk9/uDbgAAADj/OHol9uGHH5bf71eTJk0UERGhgoICjRkzRgMGDCh2fWZmpkaPHl3OUwIAACDcOHol9p133tG0adM0ffp0rVmzRm+++aaeffZZvfnmm8WuHzFihHJycgK33bt3l/PEAAAACAcu4+BXAfh8Pj388MNKT08PHHvqqac0depUbdq06YzP9/v98nq9ysnJkcfjKctRAQAAEIKy6jVHr8QePXpUFSoEjxAREaHCwkKHJgIAAIANHN0T27t3b40ZM0Z16tRRcnKy1q5dqwkTJujWW291ciwAAACEOUe3E+Tm5uqxxx7TrFmz9OOPPyoxMVH9+/fX448/rqioqDM+n+0EAAAA4a2ses3RiD1XRCwAAEB4+6/cEwsAAACEgogFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdRyN2Hr16snlchW5paenOzkWAAAAwlykk2+enZ2tgoKCwP3169frqquu0o033ujgVAAAAAh3jkZs9erVg+6PGzdOSUlJuvzyyx2aCAAAADZwNGJ/Kz8/X1OnTlVGRoZcLlexa/Ly8pSXlxe47/f7y2s8AAAAhJGw+WDX7NmzdejQIQ0aNOi0azIzM+X1egM3n89XfgMCAAAgbLiMMcbpISQpNTVVUVFR+te//nXaNcVdifX5fMrJyZHH4ymPMQEAAFACfr9fXq+31HstLLYTfPvtt1q4cKHee++9313ndrvldrvLaSoAAACEq7DYTjB58mTVqFFDPXv2dHoUAAAAWMDxiC0sLNTkyZOVlpamyMiwuDAMAACAMOd4xC5cuFC7du3Srbfe6vQoAAAAsITjlz67deumMPlsGQAAACzh+JVYAAAAoKSIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFjH8Yj9/vvv9T//8z+qWrWqYmJi1KJFC61atcrpsQAAABDGIp1884MHD6pDhw7q3Lmz5s2bp+rVq+ubb75RlSpVnBwLAAAAYc7RiH366afl8/k0efLkwLGLLrrotOvz8vKUl5cXuO/3+8t0PgAAAIQnR7cTvP/++2rTpo1uvPFG1ahRQ3/4wx80adKk067PzMyU1+sN3Hw+XzlOCwAAgHDhMsYYp948OjpakpSRkaEbb7xR2dnZuv/++/Xyyy8rLS2tyPrirsT6fD7l5OTI4/GU29wAAAA4O36/X16vt9R7zdGIjYqKUps2bbR8+fLAsfvuu0/Z2dlasWLFGZ9fVr8UAAAAlI6y6jVHtxMkJCSoWbNmQceaNm2qXbt2OTQRAAAAbOBoxHbo0EGbN28OOrZlyxbVrVvXoYkAAABgA0cj9sEHH9TKlSs1duxYbd26VdOnT9err76q9PR0J8cCAABAmHM0Yi+99FLNmjVLb7/9tpo3b64nn3xSzz//vAYMGODkWAAAAAhzjn6w61zxwS4AAIDw9l/5wS4AAAAgFEQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6RCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6RCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6RCwAAACsE+n0AKVhwpcHFB2X7/QYAAAAOMWxw7ll8rpciQUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFjH0YgdNWqUXC5X0K1JkyZOjgQAAAALRDo9QHJyshYuXBi4Hxnp+EgAAAAIc44XY2RkpGrVquX0GAAAALCI43tiv/nmGyUmJqp+/foaMGCAdu3addq1eXl58vv9QTcAAACcfxyN2Hbt2mnKlCn66KOPlJWVpR07duiyyy5Tbm5useszMzPl9XoDN5/PV84TAwAAIBy4jDHG6SFOOnTokOrWrasJEybotttuK/J4Xl6e8vLyAvf9fr98Pp9Gfrpd0XHx5TkqAAAAzsKxw7ka3am+cnJy5PF4Su11Hd8T+1uVK1dWo0aNtHXr1mIfd7vdcrvd5TwVAAAAwo3je2J/6/Dhw9q2bZsSEhKcHgUAAABhzNGIfeihh7R06VLt3LlTy5cv13XXXaeIiAj179/fybEAAAAQ5hzdTvDdd9+pf//+OnDggKpXr66OHTtq5cqVql69upNjAQAAIMw5GrEzZsxw8u0BAABgqZC2E3z00UdatmxZ4P7EiRPVqlUr3XzzzTp48GCpDQcAAAAUJ6SIHT58eOAvGli3bp2GDRumHj16aMeOHcrIyCjVAQEAAIBThbSdYMeOHWrWrJkk6Z///Kd69eqlsWPHas2aNerRo0epDggAAACcKqQrsVFRUTp69KgkaeHCherWrZsk6YILLuCvggUAAECZC+lKbMeOHZWRkaEOHTro888/1z/+8Q9J0pYtW1S7du1SHRAAAAA4VUhXYl988UVFRkbq3XffVVZWli688EJJ0rx583T11VeX6oAAAADAqUK6ElunTh198MEHRY4/99xz5zwQAAAAcCYhXYlds2aN1q1bF7g/Z84cXXvttfrLX/6i/Pz8UhsOAAAAKE5IEXvnnXdqy5YtkqTt27erX79+qlSpkmbOnKk//elPpTogAAAAcKqQInbLli1q1aqVJGnmzJnq1KmTpk+frilTpuif//xnac4HAAAAFBHSnlhjjAoLCyX9+hVbvXr1kiT5fD7t37+/9KY7Sxktq8rj8ZT7+wIAAOD3+f1RGl0GrxvSldg2bdroqaee0ltvvaWlS5eqZ8+ekn79SxBq1qxZqgMCAAAApwopYp9//nmtWbNGQ4cO1SOPPKIGDRpIkt599121b9++VAcEAAAATuUyxpjSerFjx44pIiJCFStWLK2X/F1+v19er1c5OTlsJwAAAAhDZdVrIe2JPZ3o6OjSfDkAAACgWCFFbEFBgZ577jm988472rVrV5Hvhv35559LZTgAAACgOCHtiR09erQmTJigvn37KicnRxkZGbr++utVoUIFjRo1qpRHBAAAAIKFFLHTpk3TpEmTNGzYMEVGRqp///567bXX9Pjjj2vlypWlPSMAAAAQJKSI3bt3r1q0aCFJiouLU05OjiSpV69e+vDDD0tvOgAAAKAYIUVs7dq1tWfPHklSUlKSPv74Y0lSdna23G536U0HAAAAFCOkiL3uuuu0aNEiSdK9996rxx57TA0bNtQtt9yiW2+9tVQHBAAAAE5VKt8Tu2LFCq1YsUINGzZU7969S2Ous8L3xAIAAIS3sP6e2JSUFKWkpJTGSwEAAABndNYR+/7775/1i15zzTUhDQMAAACcjbOO2Guvvfas1rlcLhUUFIQ6DwAAAHBGZx2xhYWFZTkHAAAAcNZK9O0En3zyiZo1aya/31/ksZycHCUnJ+v//u//Sm04AAAAoDglitjnn39et99+e7GfLPN6vbrzzjs1YcKEUhsOAAAAKE6JIvbLL7/U1VdffdrHu3XrptWrV5/zUAAAAMDvKVHE7tu3TxUrVjzt45GRkfrpp5/OeSgAAADg95QoYi+88EKtX7/+tI9/9dVXSkhIOOehAAAAgN9Toojt0aOHHnvsMR07dqzIY7/88otGjhypXr16ldpwAAAAQHFKFLGPPvqofv75ZzVq1Ejjx4/XnDlzNGfOHD399NNq3Lixfv75Zz3yyCMhDTJu3Di5XC498MADIT0fAAAA548S/bWzNWvW1PLly3X33XdrxIgRMsZI+vUvOEhNTdXEiRNVs2bNEg+RnZ2tV155RRdffHGJnwsAAIDzT4kiVpLq1q2ruXPn6uDBg9q6dauMMWrYsKGqVKkS0gCHDx/WgAEDNGnSJD311FMhvQYAAADOLyXaTvBbVapU0aWXXqq2bduGHLCSlJ6erp49e6pr165nXJuXlye/3x90AwAAwPmnxFdiS9OMGTO0Zs0aZWdnn9X6zMxMjR49uoynAgAAQLgL+Ursudq9e7fuv/9+TZs2TdHR0Wf1nBEjRignJydw2717dxlPCQAAgHDkMic/nVXOZs+ereuuu04RERGBYwUFBXK5XKpQoYLy8vKCHiuO3++X1+tVTk5OsX8VLgAAAJxVVr3m2HaCK6+8UuvWrQs6NnjwYDVp0kR//vOfzxiwAAAAOH85FrHx8fFq3rx50LHY2FhVrVq1yHEAAADgtxzbEwsAAACEytFvJzjVkiVLnB4BAAAAFuBKLAAAAKxDxAIAAMA6RCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6RCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6RCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6RCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6RCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6jkZsVlaWLr74Ynk8Hnk8HqWkpGjevHlOjgQAAAALOBqxtWvX1rhx47R69WqtWrVKXbp0UZ8+ffT11187ORYAAADCnMsYY5we4rcuuOACPfPMM7rtttvOuNbv98vr9SonJ0cej6ccpgMAAEBJlFWvRZbaK52jgoICzZw5U0eOHFFKSkqxa/Ly8pSXlxe47/f7y2s8AAAAhBHHP9i1bt06xcXFye1266677tKsWbPUrFmzYtdmZmbK6/UGbj6fr5ynBQAAQDhwfDtBfn6+du3apZycHL377rt67bXXtHTp0mJDtrgrsT6fj+0EAAAAYaqsthM4HrGn6tq1q5KSkvTKK6+ccS17YgEAAMJbWfWa49sJTlVYWBh0tRUAAAA4laMf7BoxYoS6d++uOnXqKDc3V9OnT9eSJUs0f/58J8cCAABAmHM0Yn/88Ufdcsst2rNnj7xery6++GLNnz9fV111lZNjAQAAIMw5GrGvv/66k28PAAAAS4XdnlgAAADgTIhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWIeIBQAAgHWIWAAAAFiHiAUAAIB1iFgAAABYh4gFAACAdYhYAAAAWMfRiM3MzNSll16q+Ph41ahRQ9dee602b97s5EgAAACwgKMRu3TpUqWnp2vlypVasGCBjh8/rm7duunIkSNOjgUAAIAw5zLGGKeHOOmnn35SjRo1tHTpUnXq1OmM6/1+v7xer3JycuTxeMphQgAAAJREWfVaZKm9UinIycmRJF1wwQXFPp6Xl6e8vLzAfb/fXy5zAQAAILyEzQe7CgsL9cADD6hDhw5q3rx5sWsyMzPl9XoDN5/PV85TAgAAIByEzXaCu+++W/PmzdOyZctUu3btYtcUdyXW5/OxnQAAACBM/VdvJxg6dKg++OADffrpp6cNWElyu91yu93lOBkAAADCkaMRa4zRvffeq1mzZmnJkiW66KKLnBwHAAAAlnA0YtPT0zV9+nTNmTNH8fHx2rt3ryTJ6/UqJibGydEAAAAQxhzdE+tyuYo9PnnyZA0aNOiMz+crtgAAAMLbf+We2DD5TBkAAAAsEzZfsQUAAACcLSIWAAAA1iFiAQAAYB0iFgAAANYhYgEAAGAdIhYAAADWIWIBAABgHSIWAAAA1iFiAQAAYB0iFgAAANYhYgEAAGAdIhYAAADWIWIBAABgHSIWAAAA1iFiAQAAYB0iFgAAANYhYgEAAGAdIhYAAADWIWIBAABgHSIWAAAA1iFiAQAAYB0iFgAAANYhYgEAAGAdIhYAAADWIWIBAABgHSIWAAAA1iFiAQAAYB0iFgAAANYhYgEAAGAdIhYAAADWIWIBAABgHSIWAAAA1nE0Yj/99FP17t1biYmJcrlcmj17tpPjAAAAwBKORuyRI0fUsmVLTZw40ckxAAAAYJlIJ9+8e/fu6t69u5MjAAAAwEKORmxJ5eXlKS8vL3Df7/c7OA0AAACcYtUHuzIzM+X1egM3n8/n9EgAAABwgFURO2LECOXk5ARuu3fvdnokAAAAOMCq7QRut1tut9vpMQAAAOAwq67EAgAAAJLDV2IPHz6srVu3Bu7v2LFDX3zxhS644ALVqVPHwckAAAAQzhyN2FWrVqlz586B+xkZGZKktLQ0TZkyxaGpAAAAEO4cjdgrrrhCxhgnRwAAAICF2BMLAAAA6xCxAAAAsA4RCwAAAOsQsQAAALAOEQsAAADrELEAAACwDhELAAAA6xCxAAAAsA4RCwAAAOsQsQAAALAOEQsAAADrELEAAACwDhELAAAA6xCxAAAAsA4RCwAAAOsQsQAAALAOEQsAAADrELEAAACwDhELAAAA6xCxAAAAsA4RCwAAAOsQsQAAALAOEQsAAADrELEAAACwDhELAAAA6xCxAAAAsA4RCwAAAOsQsQAAALAOEQsAAADrELEAAACwDhELAAAA6xCxAAAAsE5YROzEiRNVr149RUdHq127dvr888+dHgkAAABhzPGI/cc//qGMjAyNHDlSa9asUcuWLZWamqoff/zR6dEAAAAQphyP2AkTJuj222/X4MGD1axZM7388suqVKmS3njjDadHAwAAQJhyNGLz8/O1evVqde3aNXCsQoUK6tq1q1asWFFkfV5envx+f9ANAAAA5x9HI3b//v0qKChQzZo1g47XrFlTe/fuLbI+MzNTXq83cPP5fOU1KgAAAMKI49sJSmLEiBHKyckJ3Hbv3u30SAAAAHBApJNvXq1aNUVERGjfvn1Bx/ft26datWoVWe92u+V2u8trPAAAAIQpR6/ERkVFqXXr1lq0aFHgWGFhoRYtWqSUlBQHJwMAAEA4c/RKrCRlZGQoLS1Nbdq0Udu2bfX888/ryJEjGjx4sNOjAQAAIEw5HrF9+/bVTz/9pMcff1x79+5Vq1at9NFHHxX5sBcAAABwkssYY5weIlR+v19er1c5OTnyeDxOjwMAAIBTlFWvWfXtBAAAAIBExAIAAMBCRCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6RCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6RCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6RCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDpELAAAAKxDxAIAAMA6RCwAAACsQ8QCAADAOkQsAAAArEPEAgAAwDqRTg9wLowxkiS/3+/wJAAAACjOyU472W2lxeqIPXDggCTJ5/M5PAkAAAB+z4EDB+T1ekvt9ayO2AsuuECStGvXrlL9pSA8+f1++Xw+7d69Wx6Px+lxUMY43+cXzvf5hfN9fsnJyVGdOnUC3VZarI7YChV+3dLr9Xr5Q3Ae8Xg8nO/zCOf7/ML5Pr9wvs8vJ7ut1F6vVF8NAAAAKAdELAAAAKxjdcS63W6NHDlSbrfb6VFQDjjf5xfO9/mF831+4XyfX8rqfLtMaX/fAQAAAFDGrL4SCwAAgPMTEQsAAADrELEAAACwDhELAAAA64R9xE6cOFH16tVTdHS02rVrp88///x318+cOVNNmjRRdHS0WrRooblz55bTpCgNJTnfkyZN0mWXXaYqVaqoSpUq6tq16xn/7wPhpaR/vk+aMWOGXC6Xrr322rIdEKWqpOf70KFDSk9PV0JCgtxutxo1asQ/0y1S0vP9/PPPq3HjxoqJiZHP59ODDz6oY8eOldO0OBeffvqpevfurcTERLlcLs2ePfuMz1myZIkuueQSud1uNWjQQFOmTCn5G5swNmPGDBMVFWXeeOMN8/XXX5vbb7/dVK5c2ezbt6/Y9Z999pmJiIgw48ePNxs2bDCPPvqoqVixolm3bl05T45QlPR833zzzWbixIlm7dq1ZuPGjWbQoEHG6/Wa7777rpwnRyhKer5P2rFjh7nwwgvNZZddZvr06VM+w+KclfR85+XlmTZt2pgePXqYZcuWmR07dpglS5aYL774opwnRyhKer6nTZtm3G63mTZtmtmxY4eZP3++SUhIMA8++GA5T45QzJ071zzyyCPmvffeM5LMrFmzfnf99u3bTaVKlUxGRobZsGGDeeGFF0xERIT56KOPSvS+YR2xbdu2Nenp6YH7BQUFJjEx0WRmZha7/qabbjI9e/YMOtauXTtz5513lumcKB0lPd+nOnHihImPjzdvvvlmWY2IUhTK+T5x4oRp3769ee2110xaWhoRa5GSnu+srCxTv359k5+fX14johSV9Hynp6ebLl26BB3LyMgwHTp0KNM5UfrOJmL/9Kc/meTk5KBjffv2NampqSV6r7DdTpCfn6/Vq1era9eugWMVKlRQ165dtWLFimKfs2LFiqD1kpSamnra9QgfoZzvUx09elTHjx/XBRdcUFZjopSEer6feOIJ1ahRQ7fddlt5jIlSEsr5fv/995WSkqL09HTVrFlTzZs319ixY1VQUFBeYyNEoZzv9u3ba/Xq1YEtB9u3b9fcuXPVo0ePcpkZ5au0ei2yNIcqTfv371dBQYFq1qwZdLxmzZratGlTsc/Zu3dvsev37t1bZnOidIRyvk/15z//WYmJiUX+YCD8hHK+ly1bptdff11ffPFFOUyI0hTK+d6+fbs++eQTDRgwQHPnztXWrVt1zz336Pjx4xo5cmR5jI0QhXK+b775Zu3fv18dO3aUMUYnTpzQXXfdpb/85S/lMTLK2el6ze/365dfflFMTMxZvU7YXokFSmLcuHGaMWOGZs2apejoaKfHQSnLzc3VwIEDNWnSJFWrVs3pcVAOCgsLVaNGDb366qtq3bq1+vbtq0ceeUQvv/yy06OhDCxZskRjx47VSy+9pDVr1ui9997Thx9+qCeffNLp0RDGwvZKbLVq1RQREaF9+/YFHd+3b59q1apV7HNq1apVovUIH6Gc75OeffZZjRs3TgsXLtTFF19clmOilJT0fG/btk07d+5U7969A8cKCwslSZGRkdq8ebOSkpLKdmiELJQ/3wkJCapYsaIiIiICx5o2baq9e/cqPz9fUVFRZTozQhfK+X7sscc0cOBADRkyRJLUokULHTlyRHfccYceeeQRVajANbf/JqfrNY/Hc9ZXYaUwvhIbFRWl1q1ba9GiRYFjhYWFWrRokVJSUop9TkpKStB6SVqwYMFp1yN8hHK+JWn8+PF68skn9dFHH6lNmzblMSpKQUnPd5MmTbRu3Tp98cUXgds111yjzp0764svvpDP5yvP8VFCofz57tChg7Zu3Rr4jxVJ2rJlixISEgjYMBfK+T569GiRUD35HzC/flYI/01KrddK9pmz8jVjxgzjdrvNlClTzIYNG8wdd9xhKleubPbu3WuMMWbgwIHm4YcfDqz/7LPPTGRkpHn22WfNxo0bzciRI/mKLYuU9HyPGzfOREVFmXfffdfs2bMncMvNzXXqR0AJlPR8n4pvJ7BLSc/3rl27THx8vBk6dKjZvHmz+eCDD0yNGjXMU0895dSPgBIo6fkeOXKkiY+PN2+//bbZvn27+fjjj01SUpK56aabnPoRUAK5ublm7dq1Zu3atUaSmTBhglm7dq359ttvjTHGPPzww2bgwIGB9Se/Ymv48OFm48aNZuLEif99X7FljDEvvPCCqVOnjomKijJt27Y1K1euDDx2+eWXm7S0tKD177zzjmnUqJGJiooyycnJ5sMPPyzniXEuSnK+69atayQVuY0cObL8B0dISvrn+7eIWPuU9HwvX77ctGvXzrjdblO/fn0zZswYc+LEiXKeGqEqyfk+fvy4GTVqlElKSjLR0dHG5/OZe+65xxw8eLD8B0eJLV68uNh/H588x2lpaebyyy8v8pxWrVqZqKgoU79+fTN58uQSv6/LGK7TAwAAwC5huycWAAAAOB0iFgAAANYhYgEAAGAdIhYAAADWIWIBAABgHSIWAAAA1iFiAQAAYB0iFgAAANYhYgGgjAwaNEjXXnvtOb3Gzp075XK59MUXX5x2zZIlS+RyuXTo0CFJ0pQpU1S5cuXA46NGjVKrVq3OaQ4ACDdELADo1+B0uVxyuVyKiopSgwYN9MQTT+jEiRNOj3ZG7du31549e+T1eot9/KGHHtKiRYsC90sjrgHAaZFODwAA4eLqq6/W5MmTlZeXp7lz5yo9PV0VK1bUiBEjgtbl5+crKirKoSmLioqKUq1atU77eFxcnOLi4spxIgAoe1yJBYD/cLvdqlWrlurWrau7775bXbt21fvvvx+4cjlmzBglJiaqcePGkqR169apS5cuiomJUdWqVXXHHXfo8OHDRV539OjRql69ujwej+666y7l5+cHHvvoo4/UsWNHVa5cWVWrVlWvXr20bdu2Iq+xadMmtW/fXtHR0WrevLmWLl0aeOzU7QSn+u12glGjRunNN9/UnDlzAleelyxZoi5dumjo0KFBz/vpp58UFRUVdBUXAMIFEQsApxETExMIzkWLFmnz5s1asGCBPvjgAx05ckSpqamqUqWKsrOzNXPmTC1cuLBICC5atEgbN27UkiVL9Pbbb+u9997T6NGjA48fOXJEGRkZWrVqlRYtWqQKFSrouuuuU2FhYdDrDB8+XMOGDdPatWuVkpKi3r1768CBAyX+mR566CHddNNNuvrqq7Vnzx7t2bNH7du315AhQzR9+nTl5eUF1k6dOlUXXnihunTpUuL3AYCyRsQCwCmMMVq4cKHmz58fCLjY2Fi99tprSk5OVnJysqZPn65jx47p73//u5o3b64uXbroxRdf1FtvvaV9+/YFXisqKkpvvPGGkpOT1bNnTz3xxBP63//930Ck/vGPf9T111+vBg0aqFWrVnrjjTe0bt06bdiwIWimoUOH6o9//KOaNm2qrKwseb1evf766yX+2eLi4hQTExO46lyrVi1FRUXp+uuvlyTNmTMnsHbKlCmBvcIAEG6IWAD4jw8++EBxcXGKjo5W9+7d1bdvX40aNUqS1KJFi6B9sBs3blTLli0VGxsbONahQwcVFhZq8+bNgWMtW7ZUpUqVAvdTUlJ0+PBh7d69W5L0zTffqH///qpfv748Ho/q1asnSdq1a1fQbCkpKYH/HRkZqTZt2mjjxo2l9rNHR0dr4MCBeuONNyRJa9as0fr16zVo0KBSew8AKE18sAsA/qNz587KyspSVFSUEhMTFRn5//8R+dtYLU29e/dW3bp1NWnSJCUmJqqwsFDNmzcP2jdbXoYMGaJWrVrpu+++0+TJk9WlSxfVrVu33OcAgLPBlVgA+I/Y2Fg1aNBAderUCQrY4jRt2lRffvmljhw5Ejj22WefqUKFCoEPfknSl19+qV9++SVwf+XKlYqLi5PP59OBAwe0efNmPfroo7ryyivVtGlTHTx4sNj3W7lyZeB/nzhxQqtXr1bTpk1D+jmjoqJUUFBQ5HiLFi3Upk0bTZo0SdOnT9ett94a0usDQHkgYgEgBAMGDFB0dLTS0tK0fv16LV68WPfee68GDhyomjVrBtbl5+frtttu04YNGzR37lyNHDlSQ4cOVYUKFVSlShVVrVpVr776qrZu3apPPvlEGRkZxb7fxIkTNWvWLG3atEnp6ek6ePBgyJFZr149ffXVV9q8ebP279+v48ePBx4bMmSIxo0bJ2OMrrvuupBeHwDKAxELACGoVKmS5s+fr59//lmXXnqpbrjhBl155ZV68cUXg9ZdeeWVatiwoTp16qS+ffvqmmuuCeyzrVChgmbMmKHVq1erefPmevDBB/XMM88U+37jxo3TuHHj1LJlSy1btkzvv/++qlWrFtLst99+uxo3bqw2bdqoevXq+uyzzwKP9e/fX5GRkerfv7+io6NDen0AKA8uY4xxeggAQHjYuXOnkpKSlJ2drUsuucTpcQDgtIhYAICOHz+uAwcO6KGHHtKOHTuCrs4CQDhiOwEAQJ999pkSEhKUnZ2tl19+2elxAOCMuBILAAAA63AlFgAAANYhYgEAAGAdIhYAAADWIWIBAABgHSIWAAAA1iFiAQAAYB0iFgAAANYhYgEAAGCd/weP3OjT8Kzb1wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = np.arange(10)\n",
    "\n",
    "probabilities = prediction.flatten()\n",
    "# Create a horizontal bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(classes, probabilities, color='skyblue')\n",
    "plt.yticks(classes)\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Class')\n",
    "plt.title('Class Probabilities')\n",
    "plt.xlim(0, 1)  # Since it's a probability, we limit the x-axis to [0, 1]\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step\n",
      "Struggling digit pairs (True Label, Predicted Label): Counter({(9.0, 1): 36, (5.0, 9): 34, (9.0, 5): 22, (5.0, 1): 21, (4.0, 1): 20, (0.0, 2): 19, (3.0, 8): 19, (6.0, 8): 17, (8.0, 6): 17, (2.0, 7): 15, (2.0, 0): 15, (1.0, 9): 14, (8.0, 3): 14, (1.0, 4): 14, (2.0, 8): 14, (5.0, 4): 13, (7.0, 2): 12, (8.0, 2): 12, (2.0, 3): 12, (0.0, 7): 11, (2.0, 4): 11, (9.0, 9): 11, (5.0, 5): 11, (2.0, 2): 11, (3.0, 2): 10, (3.0, 3): 10, (4.0, 2): 9, (4.0, 4): 9, (1.0, 5): 9, (7.0, 7): 9, (7.0, 5): 9, (6.0, 6): 8, (6.0, 7): 8, (0.0, 4): 8, (0.0, 0): 8, (6.0, 3): 7, (3.0, 6): 7, (8.0, 1): 7, (9.0, 3): 7, (7.0, 8): 7, (3.0, 9): 6, (9.0, 2): 6, (0.0, 6): 6, (1.0, 1): 6, (4.0, 5): 6, (8.0, 4): 5, (8.0, 5): 5, (0.0, 3): 5, (3.0, 5): 5, (6.0, 0): 5, (6.0, 5): 5, (8.0, 8): 4, (3.0, 7): 4, (9.0, 0): 4, (4.0, 0): 4, (6.0, 1): 4, (7.0, 6): 4, (0.0, 9): 4, (1.0, 2): 4, (6.0, 4): 3, (1.0, 8): 3, (7.0, 9): 3, (7.0, 4): 3, (7.0, 1): 3, (3.0, 0): 3, (8.0, 9): 3, (4.0, 7): 3, (5.0, 7): 3, (7.0, 0): 3, (6.0, 9): 2, (3.0, 4): 2, (6.0, 2): 2, (4.0, 3): 2, (2.0, 9): 2, (5.0, 8): 2, (8.0, 7): 2, (9.0, 7): 2, (4.0, 8): 2, (5.0, 6): 2, (9.0, 4): 2, (9.0, 8): 2, (3.0, 1): 1, (7.0, 3): 1, (1.0, 0): 1, (5.0, 0): 1, (0.0, 1): 1, (5.0, 2): 1, (1.0, 7): 1, (1.0, 6): 1, (4.0, 6): 1, (5.0, 3): 1, (2.0, 6): 1, (0.0, 8): 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# Dictionary to count how often each digit is predicted with low confidence\n",
    "struggling_digits = Counter()\n",
    "\n",
    "struggling_pairs = Counter()\n",
    "\n",
    "# Iterate through predictions and corresponding true labels\n",
    "for probs, true_label in zip(model.predict(X_train), Y_train):\n",
    "    predicted_label = np.argmax(probs)  # Get the predicted class (class with highest probability)\n",
    "    max_prob = np.max(probs)  # Get the highest probability\n",
    "\n",
    "    # If the model is uncertain or if the prediction is incorrect\n",
    "    if max_prob < threshold or predicted_label != true_label:\n",
    "        struggling_pairs[(true_label, predicted_label)] += 1  # Count the true-predicted pair\n",
    "\n",
    "# Output the struggling digit pairs (true label, predicted label)\n",
    "print(\"Struggling digit pairs (True Label, Predicted Label):\", struggling_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m891/891\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# Dictionary to count the struggling pairs (true_label, predicted_label)\n",
    "struggling_pairs = Counter()\n",
    "\n",
    "# Iterate through predictions and corresponding true labels\n",
    "for probs, true_label in zip(predictions, Y_train):\n",
    "    predicted_label = np.argmax(probs)  # Get the predicted class (class with highest probability)\n",
    "    max_prob = np.max(probs)  # Get the highest probability\n",
    "    # If the model is uncertain or if the prediction is incorrect\n",
    "    if max_prob < threshold or predicted_label != true_label:\n",
    "        struggling_pairs[(int(true_label), int(predicted_label))] += 1  # Count the true-predicted pair\n",
    "\n",
    "# Initialize a confusion matrix (10x10 since we have digits 0-9)\n",
    "confusion_matrix = np.zeros((10, 10))\n",
    "\n",
    "# Populate the confusion matrix with the struggling pairs\n",
    "for (true_label, predicted_label), count in struggling_pairs.items():\n",
    "    confusion_matrix[true_label, predicted_label] = count\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='coolwarm', fmt='g')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Struggling Digit Pairs (True Label vs. Predicted Label)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 202ms/step - accuracy: 0.4459 - loss: 3.3447 - val_accuracy: 0.9026 - val_loss: 0.3032 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 198ms/step - accuracy: 0.9179 - loss: 0.2596 - val_accuracy: 0.9176 - val_loss: 0.2454 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 203ms/step - accuracy: 0.9513 - loss: 0.1504 - val_accuracy: 0.9354 - val_loss: 0.1935 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 211ms/step - accuracy: 0.9630 - loss: 0.1121 - val_accuracy: 0.9279 - val_loss: 0.2077 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 202ms/step - accuracy: 0.9828 - loss: 0.0533 - val_accuracy: 0.9472 - val_loss: 0.1909 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m185/713\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40\u001b[0m 190ms/step - accuracy: 0.9898 - loss: 0.0329"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdamW(learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m, weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.005\u001b[39m)\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer \u001b[38;5;241m=\u001b[39m optimizer, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 21\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, callbacks \u001b[38;5;241m=\u001b[39m [EarlyStoppingCB, LearningRateCB])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(X_train[0].shape))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation = \"relu\", kernel_initializer = \"he_normal\", padding = \"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3,3), activation = \"relu\", kernel_initializer = \"he_normal\", padding = \"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\", kernel_initializer = \"he_normal\", padding = \"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\", kernel_initializer = \"he_normal\", padding = \"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(tf.keras.layers.Conv2D(128, (3,3), activation = \"relu\", kernel_initializer = \"he_normal\", padding = \"same\"))\n",
    "model.add(tf.keras.layers.Conv2D(128, (3,3), activation = \"relu\", kernel_initializer = \"he_normal\", padding = \"same\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation = \"relu\", kernel_initializer = \"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "EarlyStoppingCB = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 3, restore_best_weights = \"True\")\n",
    "LearningRateCB = tf.keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience = 1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate = 0.001, weight_decay = 0.005)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "history = model.fit(X_train, Y_train, epochs = 30, validation_split=0.2, callbacks = [EarlyStoppingCB, LearningRateCB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.2751 - loss: 6.7857 - val_accuracy: 0.3643 - val_loss: 2.3307 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4323 - loss: 2.0958 - val_accuracy: 0.5243 - val_loss: 1.6699 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5302 - loss: 1.6069 - val_accuracy: 0.5185 - val_loss: 1.6058 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5681 - loss: 1.4307 - val_accuracy: 0.6060 - val_loss: 1.3237 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6070 - loss: 1.2590 - val_accuracy: 0.5980 - val_loss: 1.2620 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6384 - loss: 1.1299 - val_accuracy: 0.6201 - val_loss: 1.2541 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6465 - loss: 1.1671 - val_accuracy: 0.6558 - val_loss: 1.1363 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6728 - loss: 1.0442 - val_accuracy: 0.6392 - val_loss: 1.1568 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6952 - loss: 0.9416 - val_accuracy: 0.6702 - val_loss: 1.0912 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7147 - loss: 0.8912 - val_accuracy: 0.6560 - val_loss: 1.0965 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7118 - loss: 0.9212 - val_accuracy: 0.6762 - val_loss: 1.0521 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7364 - loss: 0.7955 - val_accuracy: 0.6558 - val_loss: 1.1282 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7431 - loss: 0.7829 - val_accuracy: 0.6794 - val_loss: 1.1108 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7742 - loss: 0.6661 - val_accuracy: 0.7015 - val_loss: 0.9890 - learning_rate: 5.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7908 - loss: 0.6253 - val_accuracy: 0.7230 - val_loss: 0.8937 - learning_rate: 5.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8036 - loss: 0.5831 - val_accuracy: 0.7120 - val_loss: 0.9726 - learning_rate: 5.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8090 - loss: 0.5656 - val_accuracy: 0.7444 - val_loss: 0.8491 - learning_rate: 5.0000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8155 - loss: 0.5452 - val_accuracy: 0.7213 - val_loss: 0.9739 - learning_rate: 5.0000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8189 - loss: 0.5341 - val_accuracy: 0.7432 - val_loss: 0.9080 - learning_rate: 5.0000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8367 - loss: 0.4721 - val_accuracy: 0.7683 - val_loss: 0.7528 - learning_rate: 2.5000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.4326 - val_accuracy: 0.7657 - val_loss: 0.7903 - learning_rate: 2.5000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.4145 - val_accuracy: 0.7730 - val_loss: 0.7705 - learning_rate: 2.5000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8664 - loss: 0.3852 - val_accuracy: 0.7848 - val_loss: 0.7368 - learning_rate: 1.2500e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8747 - loss: 0.3645 - val_accuracy: 0.7800 - val_loss: 0.7536 - learning_rate: 1.2500e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8776 - loss: 0.3551 - val_accuracy: 0.7811 - val_loss: 0.7495 - learning_rate: 1.2500e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8797 - loss: 0.3427 - val_accuracy: 0.7872 - val_loss: 0.7325 - learning_rate: 6.2500e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8861 - loss: 0.3331 - val_accuracy: 0.7871 - val_loss: 0.7358 - learning_rate: 6.2500e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8881 - loss: 0.3262 - val_accuracy: 0.7867 - val_loss: 0.7432 - learning_rate: 6.2500e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8920 - loss: 0.3208 - val_accuracy: 0.7893 - val_loss: 0.7326 - learning_rate: 3.1250e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8945 - loss: 0.3147 - val_accuracy: 0.7874 - val_loss: 0.7339 - learning_rate: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape = [129, 71]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "early_stopping_cb= tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "lr_scheduler= tf.keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience= 2)\n",
    "history = model.fit(X_train, Y_train, epochs = 30, validation_split = 0.2, callbacks= [early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well this works okay, the validation accuracy is not perfect, but it's satisfying. Let's try with swish activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.2560 - loss: 5.7668 - val_accuracy: 0.4313 - val_loss: 2.0350 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4197 - loss: 2.0398 - val_accuracy: 0.4654 - val_loss: 1.7794 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5057 - loss: 1.6367 - val_accuracy: 0.5590 - val_loss: 1.4783 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5581 - loss: 1.3812 - val_accuracy: 0.5424 - val_loss: 1.4503 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5839 - loss: 1.2322 - val_accuracy: 0.6027 - val_loss: 1.1591 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6182 - loss: 1.1189 - val_accuracy: 0.6308 - val_loss: 1.0953 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6409 - loss: 1.0729 - val_accuracy: 0.6459 - val_loss: 1.0590 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.6564 - loss: 1.0196 - val_accuracy: 0.6748 - val_loss: 0.9762 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.6800 - loss: 0.9480 - val_accuracy: 0.6662 - val_loss: 1.0184 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6939 - loss: 0.9058 - val_accuracy: 0.6843 - val_loss: 0.9551 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7095 - loss: 0.8560 - val_accuracy: 0.7025 - val_loss: 0.9001 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7151 - loss: 0.8350 - val_accuracy: 0.6936 - val_loss: 0.9266 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7330 - loss: 0.7860 - val_accuracy: 0.7222 - val_loss: 0.8378 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7457 - loss: 0.7409 - val_accuracy: 0.6909 - val_loss: 0.9447 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7421 - loss: 0.7474 - val_accuracy: 0.7360 - val_loss: 0.8360 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7678 - loss: 0.6847 - val_accuracy: 0.7341 - val_loss: 0.8291 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7652 - loss: 0.6828 - val_accuracy: 0.7444 - val_loss: 0.8019 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7760 - loss: 0.6622 - val_accuracy: 0.7079 - val_loss: 0.9320 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.6462 - val_accuracy: 0.7211 - val_loss: 0.9440 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8157 - loss: 0.5434 - val_accuracy: 0.7393 - val_loss: 0.8377 - learning_rate: 5.0000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8320 - loss: 0.4942 - val_accuracy: 0.7495 - val_loss: 0.8236 - learning_rate: 5.0000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8505 - loss: 0.4393 - val_accuracy: 0.7637 - val_loss: 0.7888 - learning_rate: 2.5000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8534 - loss: 0.4154 - val_accuracy: 0.7655 - val_loss: 0.7988 - learning_rate: 2.5000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8602 - loss: 0.3971 - val_accuracy: 0.7639 - val_loss: 0.8009 - learning_rate: 2.5000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8719 - loss: 0.3643 - val_accuracy: 0.7767 - val_loss: 0.7779 - learning_rate: 1.2500e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8781 - loss: 0.3497 - val_accuracy: 0.7730 - val_loss: 0.7866 - learning_rate: 1.2500e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8808 - loss: 0.3383 - val_accuracy: 0.7718 - val_loss: 0.8005 - learning_rate: 1.2500e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8847 - loss: 0.3270 - val_accuracy: 0.7821 - val_loss: 0.7672 - learning_rate: 6.2500e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8918 - loss: 0.3165 - val_accuracy: 0.7820 - val_loss: 0.7736 - learning_rate: 6.2500e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8934 - loss: 0.3107 - val_accuracy: 0.7807 - val_loss: 0.7769 - learning_rate: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape = [129, 71]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"swish\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"swish\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation = \"swish\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "early_stopping_cb= tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "lr_scheduler= tf.keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience= 2)\n",
    "history = model.fit(X_train, Y_train, epochs = 30, validation_split = 0.2, callbacks= [early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so changing to swish activation function doesn't change anything. Let's move back to the ReLu and increase the number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.3111 - loss: 10.0604 - val_accuracy: 0.5034 - val_loss: 1.7093 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.5414 - loss: 1.7691 - val_accuracy: 0.6476 - val_loss: 1.2296 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.6448 - loss: 1.2819 - val_accuracy: 0.6769 - val_loss: 1.2401 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.6993 - loss: 1.0510 - val_accuracy: 0.7043 - val_loss: 1.0639 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.7346 - loss: 0.8924 - val_accuracy: 0.7179 - val_loss: 0.9688 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.7602 - loss: 0.8421 - val_accuracy: 0.7485 - val_loss: 0.8364 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.7875 - loss: 0.6931 - val_accuracy: 0.7376 - val_loss: 0.8759 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.8014 - loss: 0.6475 - val_accuracy: 0.7828 - val_loss: 0.7538 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.8176 - loss: 0.5633 - val_accuracy: 0.7811 - val_loss: 0.7226 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.8358 - loss: 0.5042 - val_accuracy: 0.7813 - val_loss: 0.7088 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.8402 - loss: 0.4682 - val_accuracy: 0.7820 - val_loss: 0.7220 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.8478 - loss: 0.4541 - val_accuracy: 0.7799 - val_loss: 0.7818 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.8859 - loss: 0.3365 - val_accuracy: 0.8344 - val_loss: 0.5766 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9025 - loss: 0.2829 - val_accuracy: 0.8370 - val_loss: 0.5985 - learning_rate: 5.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9147 - loss: 0.2516 - val_accuracy: 0.8397 - val_loss: 0.5819 - learning_rate: 5.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9358 - loss: 0.1864 - val_accuracy: 0.8628 - val_loss: 0.5170 - learning_rate: 2.5000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9459 - loss: 0.1582 - val_accuracy: 0.8641 - val_loss: 0.5238 - learning_rate: 2.5000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9511 - loss: 0.1384 - val_accuracy: 0.8572 - val_loss: 0.5920 - learning_rate: 2.5000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.9603 - loss: 0.1153 - val_accuracy: 0.8732 - val_loss: 0.5406 - learning_rate: 1.2500e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.9663 - loss: 0.0961 - val_accuracy: 0.8725 - val_loss: 0.5646 - learning_rate: 1.2500e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9709 - loss: 0.0856 - val_accuracy: 0.8762 - val_loss: 0.5491 - learning_rate: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape = [129, 71]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(400, activation = \"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(300, activation = \"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(200, activation = \"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "early_stopping_cb= tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "lr_scheduler= tf.keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience= 2)\n",
    "history = model.fit(X_train, Y_train, epochs = 30, validation_split = 0.2, callbacks= [early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! The train accuracy reached a whopping 97%, unfortunately, the validation accuracy is 10 percent points less, which is an unacceptable proof of overfitting. Therefore, we will try to change the optimizer to AdamW to introduce weight_decay and regularization. Let's start with weight decay = 0.0075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.2981 - loss: 10.5311 - val_accuracy: 0.5232 - val_loss: 1.6547 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.5555 - loss: 1.6789 - val_accuracy: 0.6078 - val_loss: 1.2272 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.6543 - loss: 1.1291 - val_accuracy: 0.6881 - val_loss: 0.9643 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.7051 - loss: 0.9096 - val_accuracy: 0.7465 - val_loss: 0.7937 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.7320 - loss: 0.8024 - val_accuracy: 0.7374 - val_loss: 0.8175 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.7706 - loss: 0.6918 - val_accuracy: 0.7362 - val_loss: 0.8411 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.8288 - loss: 0.5105 - val_accuracy: 0.8174 - val_loss: 0.5699 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.8461 - loss: 0.4502 - val_accuracy: 0.8118 - val_loss: 0.6095 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.8572 - loss: 0.4182 - val_accuracy: 0.8330 - val_loss: 0.5321 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.8653 - loss: 0.3927 - val_accuracy: 0.8063 - val_loss: 0.6390 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.8691 - loss: 0.3879 - val_accuracy: 0.8235 - val_loss: 0.6066 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9061 - loss: 0.2766 - val_accuracy: 0.8535 - val_loss: 0.5022 - learning_rate: 2.5000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.9200 - loss: 0.2333 - val_accuracy: 0.8546 - val_loss: 0.5099 - learning_rate: 2.5000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - accuracy: 0.9328 - loss: 0.2015 - val_accuracy: 0.8544 - val_loss: 0.5226 - learning_rate: 2.5000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9413 - loss: 0.1747 - val_accuracy: 0.8684 - val_loss: 0.4853 - learning_rate: 1.2500e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9498 - loss: 0.1528 - val_accuracy: 0.8698 - val_loss: 0.4846 - learning_rate: 1.2500e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - accuracy: 0.9589 - loss: 0.1291 - val_accuracy: 0.8702 - val_loss: 0.5031 - learning_rate: 1.2500e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9643 - loss: 0.1164 - val_accuracy: 0.8709 - val_loss: 0.5143 - learning_rate: 1.2500e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9668 - loss: 0.1029 - val_accuracy: 0.8760 - val_loss: 0.5042 - learning_rate: 6.2500e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9735 - loss: 0.0913 - val_accuracy: 0.8725 - val_loss: 0.5208 - learning_rate: 6.2500e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - accuracy: 0.9746 - loss: 0.0836 - val_accuracy: 0.8763 - val_loss: 0.5065 - learning_rate: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape = [129, 71]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(400, activation = \"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(300, activation = \"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(200, activation = \"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate = 0.001, weight_decay=0.0075)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "early_stopping_cb= tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "lr_scheduler= tf.keras.callbacks.ReduceLROnPlateau(factor = 0.5, patience= 2)\n",
    "history = model.fit(X_train, Y_train, epochs = 30, validation_split = 0.2, callbacks= [early_stopping_cb, lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm that doesn't seem like a lot of help, let's try reducing the number of neurons and add more layers... but that will come in the next episode!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
