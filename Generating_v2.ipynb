{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow==2.9.0\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(images, n_cols=None):\n",
    "    '''visualizes fake images'''\n",
    "    #display.clear_output(wait=False)  \n",
    "\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    \n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap = \"binary\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, n_classes):\n",
    "  # label input\n",
    "  in_label = keras.layers.Input(shape=(1,))\n",
    "  # embedding for categorical input\n",
    "  li = keras.layers.Embedding(n_classes, 50)(in_label)\n",
    "  # linear multiplication\n",
    "  n_nodes = 7 * 7\n",
    "  li = keras.layers.Dense(n_nodes)(li)\n",
    "  # reshape to additional channel\n",
    "  li = keras.layers.Reshape((7, 7, 1))(li)\n",
    "  # image generator input\n",
    "  in_lat = keras.layers.Input(shape=(latent_dim,))\n",
    "  # foundation for 7x7 image\n",
    "  n_nodes = 128 * 7 * 7\n",
    "  gen = keras.layers.Dense(n_nodes)(in_lat)\n",
    "\n",
    "  gen = keras.layers.LeakyReLU(alpha=0.2)(gen)\n",
    "  gen = keras.layers.Reshape((7, 7, 128))(gen)\n",
    "  # merge image gen and label input\n",
    "  merge = keras.layers.Concatenate()([gen, li])\n",
    "  # upsample to 14x14\n",
    "  gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', \n",
    "                                     activation=keras.layers.LeakyReLU(alpha=0.2))(merge)\n",
    "  gen = keras.layers.BatchNormalization()(gen)\n",
    "  # upsample to 28x28\n",
    "  gen = keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', \n",
    "                                     activation=keras.layers.LeakyReLU(alpha=0.2))(gen)\n",
    "  gen = keras.layers.BatchNormalization()(gen)\n",
    "  # output\n",
    "  out_layer = keras.layers.Conv2D(1, (7,7), activation='tanh', padding='same')(gen)\n",
    "  # define model\n",
    "  model = keras.Model([in_lat, in_label], out_layer)\n",
    "  return model\n",
    "\n",
    "\n",
    "img_dim = 28\n",
    "num_classes = 26\n",
    "latent_dim = 50\n",
    "\n",
    "generator = define_generator(latent_dim, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "def define_discriminator(in_shape=(28, 28, 1), n_classes=num_classes):\n",
    "  in_label = keras.layers.Input(shape=(1,))\n",
    "  li = keras.layers.Embedding(n_classes, 50)(in_label)\n",
    "\n",
    "  n_nodes = in_shape[0] * in_shape[1]\n",
    "  li=keras.layers.Dense(n_nodes)(li)\n",
    "\n",
    "  li=keras.layers.Reshape((in_shape[0], in_shape[1], 1))(li)\n",
    "\n",
    "  in_image = keras.layers.Input(shape=in_shape)\n",
    "\n",
    "  merge = keras.layers.Concatenate()([in_image, li])\n",
    "\n",
    "  #downsample\n",
    "  fe=keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', \n",
    "                         activation=keras.layers.LeakyReLU(alpha=0.2))(merge)\n",
    "  fe=keras.layers.Dropout(0.4)(fe)\n",
    "\n",
    "  #downsample\n",
    "  fe=keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', \n",
    "                         activation=keras.layers.LeakyReLU(alpha=0.2))(fe)\n",
    "  fe=keras.layers.Dropout(0.4)(fe)\n",
    "\n",
    "  fe = keras.layers.Flatten()(fe)\n",
    "\n",
    "  out_layer = keras.layers.Dense(1, activation='sigmoid')(fe)\n",
    "\n",
    "  model = keras.Model([in_image, in_label], out_layer)\n",
    "\n",
    "  opt = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "discriminator = define_discriminator()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the Conditional GAN\n",
    "def define_gan(generator, discriminator):\n",
    "  #make discriminator non trainable\n",
    "  discriminator.trainable = False\n",
    "\n",
    "  #get noise and label from generator\n",
    "  gen_noise, gen_label = generator.input\n",
    "\n",
    "  #get output from generator\n",
    "  gen_output = generator.output\n",
    "\n",
    "  #connect image and label input from generator as inputs to discriminator\n",
    "  gan_output = discriminator([gen_output, gen_label])\n",
    "\n",
    "  #define the GAN model. \n",
    "  model= keras.Model([gen_noise, gen_label], gan_output)\n",
    "\n",
    "  #compile model\n",
    "  opt = keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "  model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "  return model\n",
    "\n",
    "def load_dataset():\n",
    "  # download the training images\n",
    "  (X_train, y_train), (_, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "  # normalize pixel values\n",
    "  X_train = X_train.astype(np.float32) / 255\n",
    "\n",
    "  # reshape and rescale\n",
    "  X_train = X_train.reshape(-1, 28, 28, 1) * 2. - 1.\n",
    "\n",
    "  return [X_train, y_train]\n",
    "\n",
    "def get_dataset_samples(dataset, n_samples):\n",
    "  images, labels = dataset\n",
    "\n",
    "  ix = np.random.randint(0, images.shape[0], n_samples)\n",
    "\n",
    "  X, labels = images[ix], labels[ix]\n",
    "\n",
    "  y = np.ones((n_samples, 1))\n",
    "  return [X, labels], y\n",
    "\n",
    "def generate_noise(noise_size, n_samples, n_classes=10):\n",
    "  #generate noise\n",
    "  x_input = np.random.randn(noise_size * n_samples)\n",
    "  \n",
    "  #shape to adjust to batch size\n",
    "  z_input = x_input.reshape(n_samples, noise_size)\n",
    "\n",
    "  #generate labels\n",
    "  labels = np.random.randint(0, n_classes, n_samples)\n",
    "  return [z_input, labels]\n",
    "\n",
    "def generate_fake_samples(generator, latent_dim, n_samples): \n",
    "  #get the noise calling the function\n",
    "  z_input, labels_input = generate_noise(latent_dim, n_samples)\n",
    "\n",
    "  images = generator.predict([z_input, labels_input])\n",
    "\n",
    "  #create class labes\n",
    "  y = np.zeros((n_samples, 1))\n",
    "  return [images, labels_input], y\n",
    "\n",
    "def train_gan(generator, discriminator, GAN, dataset, noise_size=100, n_epochs=30, n_batch=512):\n",
    "  steps = int(dataset[0].shape[0] / n_batch)\n",
    "  half_batch = int(n_batch / 2)\n",
    "  # manually enumerate epochs\n",
    "  for e in range(n_epochs):\n",
    "    # enumerate batches over the training set\n",
    "    for s in range(steps):\n",
    "      #TRAIN THE DISCRIMINATOR\n",
    "      # get randomly selected 'real' samples\n",
    "      [X_real, labels_real], y_real = get_dataset_samples(dataset, half_batch)\n",
    "      # update discriminator model weights\n",
    "      d_loss1, _ = discriminator.train_on_batch([X_real, labels_real], y_real)\n",
    "      # generate 'fake' examples\n",
    "      [X_fake, labels], y_fake = generate_fake_samples(generator, noise_size, half_batch)\n",
    "      # update discriminator model weights\n",
    "      d_loss2, _ = discriminator.train_on_batch([X_fake, labels], y_fake)\n",
    "\n",
    "      #TRAIN THE GENERATOR\n",
    "      # prepare points in latent space as input for the generator\n",
    "      [z_input, labels_input] = generate_noise(noise_size, n_batch)\n",
    "      # create inverted labels for the fake samples\n",
    "      y_gan = np.ones((n_batch, 1))\n",
    "      # update the generator via the discriminator's error\n",
    "      g_loss = GAN.train_on_batch([z_input, labels_input], y_gan)\n",
    "      # summarize loss on this batch\n",
    "      print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
    "      (e+1, s+1, steps, d_loss1, d_loss2, g_loss))\n",
    "   \n",
    "    \n",
    "  # save the generator model\n",
    "  generator.save('cgan_generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset()\n",
    "GAN = define_gan(generator, discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001BB8813DF80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001BB9DE6DF80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_gan(generator, discriminator, GAN, dataset, latent_dim, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, n_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 91\u001b[0m, in \u001b[0;36mtrain_gan\u001b[1;34m(generator, discriminator, GAN, dataset, noise_size, n_epochs, n_batch)\u001b[0m\n\u001b[0;32m     89\u001b[0m     g_loss \u001b[38;5;241m=\u001b[39m GAN\u001b[38;5;241m.\u001b[39mtrain_on_batch([z_input, labels_input], y_gan)\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# summarize loss on this batch\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, d1=\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m, d2=\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m g=\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m     92\u001b[0m     (e\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, s\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, steps, d_loss1, d_loss2, g_loss))\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# save the generator model\u001b[39;00m\n\u001b[0;32m     96\u001b[0m generator\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcgan_generator.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not list"
     ]
    }
   ],
   "source": [
    "train_gan(generator, discriminator, GAN, dataset, latent_dim, n_epochs=30, n_batch=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "y_train = tf.keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "\n",
    "gan = GAN(discriminator=dis, generator=gen, latent_dim=latent_dim, num_classes=num_classes)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001, clipvalue=1.0),\n",
    "    g_optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_compare_image(generator, latent_dim, label, num_classes):\n",
    "    # Step 1: Display the actual image from the dataset\n",
    "    plt.figure(figsize=(3, 1))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(X[np.where(Y == label)[0][0]], cmap='gray', interpolation='nearest')\n",
    "    plt.title(\"Real\")\n",
    "    plt.axis('off')  # Hide the axes\n",
    "    \n",
    "    # Step 2: Generate a random latent vector (noise)\n",
    "    random_latent_vector = np.random.normal(size=(1, latent_dim))\n",
    "    \n",
    "    # Step 3: Create a one-hot encoded label for the condition\n",
    "    one_hot_label = np.zeros((1, num_classes))\n",
    "    one_hot_label[0, label] = 1  # Set the index for the class to 1 (e.g., class 'label')\n",
    "\n",
    "    # Step 4: Generate an image using the generator model\n",
    "    generated_image = generator([random_latent_vector, one_hot_label])\n",
    "\n",
    "    # Step 5: Post-process the image (Rescale from [-1, 1] to [0, 1] for visualization)\n",
    "    generated_image = (generated_image[0, :, :, 0] + 1) / 2.0  # Assuming it's grayscale\n",
    "\n",
    "    # Step 6: Display the generated image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(generated_image, cmap='gray')\n",
    "    plt.title(\"Generated\")\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "\n",
    "    # Step 7: Show the comparison of actual vs generated images side by side\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "generate_and_compare_image(gan.generator, latent_dim=latent_dim, label=2, num_classes=num_classes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
