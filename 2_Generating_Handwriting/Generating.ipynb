{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('x_letters.npy')\n",
    "Y = np.load('y_letters.npy')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reshape([-1, 28, 28, 1])\n",
    "X_test = X_test.reshape([-1, 28, 28, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_dim, num_classes):\n",
    "    # image input 28x28x1 for grayscale images\n",
    "    image_input= layers.Input(shape=(img_dim, img_dim,1))\n",
    "    label_input= layers.Input(shape=(num_classes,))\n",
    "    flat_image= layers.Flatten()(image_input)\n",
    "    concat= layers.Concatenate()([flat_image, label_input])\n",
    "    x = layers.Dense(4, activation=\"relu\", kernel_initializer=\"he_normal\")(concat)\n",
    "    x = layers.Dropout(0.5)(x)  # Add dropout to reduce overfitting\n",
    "\n",
    "    real_or_fake= layers.Dense(1, activation='sigmoid')(x)\n",
    "    return tf.keras.Model([image_input, label_input], real_or_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_generator(img_dim, num_classes, latent_dim):\n",
    "    # Input layers\n",
    "    latent_input = layers.Input(shape=(latent_dim,))\n",
    "    label_input = layers.Input(shape=(num_classes,))\n",
    "\n",
    "    # Concatenate latent and label inputs\n",
    "    concat = layers.Concatenate()([latent_input, label_input])\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = layers.Dense(128*7*7, activation=\"relu\", kernel_initializer=\"he_normal\")(concat)\n",
    "    x = layers.LeakyReLU(negative_slope=0.1)(x)  # LeakyReLU is often used in GANs\n",
    "    x = layers.Reshape((7, 7, 128))(x)  # Reshape for Conv2DTranspose\n",
    "\n",
    "   # Transposed convolutional layers to upscale the image\n",
    "    x = layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding='same', activation='relu')(x)  # 7x7 -> 14x14\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(16, kernel_size=4, strides=2, padding='same', activation='relu')(x)  # 14x14 -> 28x28\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Final layer to produce the output image\n",
    "    generated_image = layers.Conv2DTranspose(1, kernel_size=4, strides=1, padding='same', activation='tanh')(x)  # 28x28x1\n",
    "    \n",
    "    return tf.keras.Model([latent_input, label_input], generated_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = 28\n",
    "num_classes = 26\n",
    "latent_dim = 32\n",
    "\n",
    "dis = build_discriminator(img_dim, num_classes)\n",
    "gen = build_generator(img_dim, num_classes, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, real_labels = data  # Unpack the data (images and their labels)\n",
    "        \n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # 1. Train the Discriminator:\n",
    "        # --------------------------------\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "\n",
    "        # Generate random labels for the generated images\n",
    "        random_labels = tf.random.uniform(\n",
    "            shape=(batch_size,), minval=0, maxval=self.num_classes, dtype=tf.int32\n",
    "        )\n",
    "        random_labels = tf.one_hot(random_labels, self.num_classes)\n",
    "\n",
    "        # Generate fake images conditioned on these random labels\n",
    "        generated_images = self.generator([random_latent_vectors, random_labels])\n",
    "\n",
    "        # Combine real and fake images and their labels\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        combined_labels = tf.concat([random_labels, real_labels], axis=0)\n",
    "\n",
    "        real_fake_labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)) * 0.9,  # Real labels smoothed (0.9 instead of 1)\n",
    "            tf.zeros((batch_size, 1)) + 0.1],  # Fake labels smoothed (0.1 instead of 0)\n",
    "            axis=0\n",
    "        )\n",
    "        \n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator([combined_images, combined_labels])\n",
    "            d_loss = self.loss_fn(real_fake_labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # 2. Train the Generator:\n",
    "        # --------------------------------\n",
    "        # Sample random points in the latent space again\n",
    "        random_latent_vectors = keras.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "\n",
    "        # Generate random labels again\n",
    "        random_labels = tf.random.uniform(\n",
    "            shape=(batch_size,), minval=0, maxval=self.num_classes, dtype=tf.int32\n",
    "        )\n",
    "        random_labels = tf.one_hot(random_labels, self.num_classes)\n",
    "\n",
    "        # Assemble labels that say \"all real images\" (i.e., we want the generator to fool the discriminator)\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        # Train the generator\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator([random_latent_vectors, random_labels])\n",
    "            predictions = self.discriminator([fake_images, random_labels])\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.5953 - g_loss: 0.0104\n",
      "Epoch 2/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - d_loss: 0.5810 - g_loss: 9.0001e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.4927 - g_loss: 0.0024\n",
      "Epoch 4/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3565 - g_loss: 0.0508\n",
      "Epoch 5/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3317 - g_loss: 0.1052\n",
      "Epoch 6/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3307 - g_loss: 0.1051\n",
      "Epoch 7/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3302 - g_loss: 0.1050\n",
      "Epoch 8/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3298 - g_loss: 0.1052\n",
      "Epoch 9/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3295 - g_loss: 0.1051\n",
      "Epoch 10/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3292 - g_loss: 0.1052\n",
      "Epoch 11/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3290 - g_loss: 0.1052\n",
      "Epoch 12/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3287 - g_loss: 0.1052\n",
      "Epoch 13/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3285 - g_loss: 0.1046\n",
      "Epoch 14/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3283 - g_loss: 0.1053\n",
      "Epoch 15/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3281 - g_loss: 0.1053\n",
      "Epoch 16/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3279 - g_loss: 0.1053\n",
      "Epoch 17/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3277 - g_loss: 0.1053\n",
      "Epoch 18/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3276 - g_loss: 0.1052\n",
      "Epoch 19/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3274 - g_loss: 0.1053\n",
      "Epoch 20/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3272 - g_loss: 0.1053\n",
      "Epoch 21/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3271 - g_loss: 0.1053\n",
      "Epoch 22/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3270 - g_loss: 0.1053\n",
      "Epoch 23/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3268 - g_loss: 0.1053\n",
      "Epoch 24/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3267 - g_loss: 0.1053\n",
      "Epoch 25/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3265 - g_loss: 0.1053\n",
      "Epoch 26/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3264 - g_loss: 0.1052\n",
      "Epoch 27/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3263 - g_loss: 0.1054\n",
      "Epoch 28/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3262 - g_loss: 0.1053\n",
      "Epoch 29/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3261 - g_loss: 0.1053\n",
      "Epoch 30/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3260 - g_loss: 0.1053\n",
      "Epoch 31/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3259 - g_loss: 0.1053\n",
      "Epoch 32/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3259 - g_loss: 0.1054\n",
      "Epoch 33/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3258 - g_loss: 0.1054\n",
      "Epoch 34/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3257 - g_loss: 0.1053\n",
      "Epoch 35/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3256 - g_loss: 0.1053\n",
      "Epoch 36/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3256 - g_loss: 0.1053\n",
      "Epoch 37/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3255 - g_loss: 0.1053\n",
      "Epoch 38/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3255 - g_loss: 0.1053\n",
      "Epoch 39/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3254 - g_loss: 0.1053\n",
      "Epoch 40/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3254 - g_loss: 0.1053\n",
      "Epoch 41/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3253 - g_loss: 0.1053\n",
      "Epoch 42/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3253 - g_loss: 0.1053\n",
      "Epoch 43/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3253 - g_loss: 0.1053\n",
      "Epoch 44/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3252 - g_loss: 0.1053\n",
      "Epoch 45/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3252 - g_loss: 0.1053\n",
      "Epoch 46/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3252 - g_loss: 0.1053\n",
      "Epoch 47/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3252 - g_loss: 0.1053\n",
      "Epoch 48/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3252 - g_loss: 0.1053\n",
      "Epoch 49/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3252 - g_loss: 0.1053\n",
      "Epoch 50/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3252 - g_loss: 0.1053\n",
      "Epoch 51/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 52/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 53/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 54/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 55/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 56/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 57/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 58/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 59/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 60/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 61/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 62/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 63/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 64/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 65/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 66/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 67/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 68/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 69/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 70/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 71/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 72/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 73/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 74/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 75/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 76/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 77/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 78/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 79/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 80/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 81/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 82/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 83/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 84/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 85/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 86/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 87/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 88/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 89/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 90/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 91/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 92/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 93/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 94/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 95/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 96/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 97/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 98/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 99/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 100/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3251 - g_loss: 0.1054\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x100 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ADDED BY ROB\n",
    "\n",
    "# Instantiate the models\n",
    "dis = build_discriminator(img_dim, num_classes)\n",
    "gen = build_generator(img_dim, num_classes, latent_dim)\n",
    "\n",
    "# Prepare labels for training\n",
    "y_train = tf.keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "\n",
    "# Instantiate GAN model\n",
    "gan = GAN(discriminator=dis, generator=gen, latent_dim=latent_dim, num_classes=num_classes)\n",
    "\n",
    "# Compile the GAN model\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001, clipvalue=1.0),\n",
    "    g_optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "epochs = 100\n",
    "gan.fit(X_train, y_train, epochs=epochs)\n",
    "\n",
    "# Generate image for comparison\n",
    "def generate_and_compare_image(generator, latent_dim, label, num_classes):\n",
    "    # Step 1: Display the actual image from the dataset\n",
    "    plt.figure(figsize=(3, 1))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(X[np.where(Y == label)[0][0]], cmap='gray', interpolation='nearest')\n",
    "    plt.title(\"Real\")\n",
    "    plt.axis('off')  # Hide the axes\n",
    "    \n",
    "    # Step 2: Generate a random latent vector (noise)\n",
    "    random_latent_vector = np.random.normal(size=(1, latent_dim))\n",
    "    \n",
    "    # Step 3: Create a one-hot encoded label for the condition\n",
    "    one_hot_label = np.zeros((1, num_classes))\n",
    "    one_hot_label[0, label] = 1  # Set the index for the class to 1\n",
    "    \n",
    "    # Step 4: Generate an image using the generator model\n",
    "    generated_image = generator([random_latent_vector, one_hot_label])\n",
    "    \n",
    "    # Step 5: Post-process the image (Rescale from [-1, 1] to [0, 1] for visualization)\n",
    "    generated_image = (generated_image[0, :, :, 0] + 1) / 2.0  # Assuming it's grayscale\n",
    "    \n",
    "    # Step 6: Display the generated image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(generated_image, cmap='gray')\n",
    "    plt.title(\"Generated\")\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    \n",
    "    # Step 7: Show the comparison of actual vs generated images side by side\n",
    "    plt.show()\n",
    "\n",
    "generate_and_compare_image(gan.generator, latent_dim=latent_dim, label=2, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.6898 - g_loss: 0.0025\n",
      "Epoch 2/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.5502 - g_loss: 0.0014\n",
      "Epoch 3/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3852 - g_loss: 0.0505\n",
      "Epoch 4/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3435 - g_loss: 0.0617\n",
      "Epoch 5/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3298 - g_loss: 0.1047\n",
      "Epoch 6/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3289 - g_loss: 0.1049\n",
      "Epoch 7/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3283 - g_loss: 0.1051\n",
      "Epoch 8/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3279 - g_loss: 0.1052\n",
      "Epoch 9/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3275 - g_loss: 0.1052\n",
      "Epoch 10/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3272 - g_loss: 0.1052\n",
      "Epoch 11/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3270 - g_loss: 0.1052\n",
      "Epoch 12/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3267 - g_loss: 0.1053\n",
      "Epoch 13/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3265 - g_loss: 0.1053\n",
      "Epoch 14/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3263 - g_loss: 0.1053\n",
      "Epoch 15/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3261 - g_loss: 0.1053\n",
      "Epoch 16/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3260 - g_loss: 0.1053\n",
      "Epoch 17/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3259 - g_loss: 0.1053\n",
      "Epoch 18/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3257 - g_loss: 0.1053\n",
      "Epoch 19/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3256 - g_loss: 0.1053\n",
      "Epoch 20/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3255 - g_loss: 0.1054\n",
      "Epoch 21/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3254 - g_loss: 0.1054\n",
      "Epoch 22/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3254 - g_loss: 0.1053\n",
      "Epoch 23/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3253 - g_loss: 0.1054\n",
      "Epoch 24/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3253 - g_loss: 0.1053\n",
      "Epoch 25/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3252 - g_loss: 0.1053\n",
      "Epoch 26/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3252 - g_loss: 0.1053\n",
      "Epoch 27/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3252 - g_loss: 0.1054\n",
      "Epoch 28/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3252 - g_loss: 0.1053\n",
      "Epoch 29/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3252 - g_loss: 0.1054\n",
      "Epoch 30/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3252 - g_loss: 0.1053\n",
      "Epoch 31/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 32/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 33/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 34/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 35/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 36/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 37/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 38/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 39/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 40/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 41/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 42/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 43/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 44/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 45/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 46/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 47/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 48/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 49/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 50/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 51/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 52/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 53/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 54/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 55/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 56/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 57/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 58/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 59/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 60/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 61/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 62/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 63/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1055\n",
      "Epoch 64/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 65/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 66/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 67/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 68/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 69/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 70/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 71/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 72/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 73/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 74/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 75/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 76/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 77/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 78/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 79/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 80/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 81/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 82/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 83/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 84/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 85/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 86/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 87/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 88/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 89/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 90/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 91/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 92/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n",
      "Epoch 93/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 94/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 95/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 96/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 97/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 98/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 99/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1053\n",
      "Epoch 100/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - d_loss: 0.3251 - g_loss: 0.1054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x258c6d436d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "y_train = tf.keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "\n",
    "gan = GAN(discriminator=dis, generator=gen, latent_dim=latent_dim, num_classes=num_classes)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001, clipvalue=1.0),\n",
    "    g_optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x100 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_and_compare_image(generator, latent_dim, label, num_classes):\n",
    "    # Step 1: Display the actual image from the dataset\n",
    "    plt.figure(figsize=(3, 1))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(X[np.where(Y == label)[0][0]], cmap='gray', interpolation='nearest')\n",
    "    plt.title(\"Real\")\n",
    "    plt.axis('off')  # Hide the axes\n",
    "    \n",
    "    # Step 2: Generate a random latent vector (noise)\n",
    "    random_latent_vector = np.random.normal(size=(1, latent_dim))\n",
    "    \n",
    "    # Step 3: Create a one-hot encoded label for the condition\n",
    "    one_hot_label = np.zeros((1, num_classes))\n",
    "    one_hot_label[0, label] = 1  # Set the index for the class to 1 (e.g., class 'label')\n",
    "\n",
    "    # Step 4: Generate an image using the generator model\n",
    "    generated_image = generator([random_latent_vector, one_hot_label])\n",
    "\n",
    "    # Step 5: Post-process the image (Rescale from [-1, 1] to [0, 1] for visualization)\n",
    "    generated_image = (generated_image[0, :, :, 0] + 1) / 2.0  # Assuming it's grayscale\n",
    "\n",
    "    # Step 6: Display the generated image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(generated_image, cmap='gray')\n",
    "    plt.title(\"Generated\")\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "\n",
    "    # Step 7: Show the comparison of actual vs generated images side by side\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "generate_and_compare_image(gan.generator, latent_dim=latent_dim, label=2, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_generator(img_dim, num_classes, latent_dim):\n",
    "    # Input layers\n",
    "    latent_input = layers.Input(shape=(latent_dim,))\n",
    "    label_input = layers.Input(shape=(num_classes,))\n",
    "\n",
    "    # Concatenate latent and label inputs\n",
    "    concat = layers.Concatenate()([latent_input, label_input])\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = layers.Dense(128 * 7 * 7, activation=\"relu\", kernel_initializer=\"he_normal\")(concat)\n",
    "    x = layers.LeakyReLU(negative_slope=0.1)(x)  # LeakyReLU is often used in GANs\n",
    "    x = layers.Reshape((7, 7, 128))(x)  # Reshape for Conv2DTranspose\n",
    "\n",
    "    # Transposed convolutional layers to upscale the image\n",
    "    x = layers.Conv2DTranspose(32, kernel_size=4, strides=2, padding='same', activation='relu')(x)  # 7x7 -> 14x14\n",
    "    x = layers.BatchNormalization()(x)  # Normalize for better convergence\n",
    "\n",
    "    x = layers.Conv2DTranspose(16, kernel_size=4, strides=2, padding='same', activation='relu')(x)  # 14x14 -> 28x28\n",
    "    x = layers.BatchNormalization()(x)  # Normalize for better convergence\n",
    "\n",
    "    # Final layer to produce the output image\n",
    "    generated_image = layers.Conv2DTranspose(1, kernel_size=4, strides=1, padding='same', activation='tanh')(x)  # 28x28x1\n",
    "\n",
    "    return tf.keras.Model([latent_input, label_input], generated_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = build_discriminator(img_dim, num_classes)\n",
    "gen = build_generator(img_dim, num_classes, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - d_loss: 0.5695 - g_loss: 0.6908\n",
      "Epoch 2/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.5109 - g_loss: 0.6793\n",
      "Epoch 3/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.5055 - g_loss: 0.6684\n",
      "Epoch 4/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.5009 - g_loss: 0.6576\n",
      "Epoch 5/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.4964 - g_loss: 0.6470\n",
      "Epoch 6/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.4920 - g_loss: 0.6365\n",
      "Epoch 7/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.4877 - g_loss: 0.6261\n",
      "Epoch 8/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.4835 - g_loss: 0.6158\n",
      "Epoch 9/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.4794 - g_loss: 0.6057\n",
      "Epoch 10/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.4753 - g_loss: 0.5957\n",
      "Epoch 11/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.4713 - g_loss: 0.5858\n",
      "Epoch 12/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4673 - g_loss: 0.5760\n",
      "Epoch 13/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.4635 - g_loss: 0.5663\n",
      "Epoch 14/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.4597 - g_loss: 0.5568\n",
      "Epoch 15/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.4560 - g_loss: 0.5474\n",
      "Epoch 16/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.4523 - g_loss: 0.5381\n",
      "Epoch 17/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4487 - g_loss: 0.5289\n",
      "Epoch 18/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4452 - g_loss: 0.5199\n",
      "Epoch 19/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4417 - g_loss: 0.5109\n",
      "Epoch 20/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4383 - g_loss: 0.5021\n",
      "Epoch 21/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4349 - g_loss: 0.4934\n",
      "Epoch 22/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4316 - g_loss: 0.4848\n",
      "Epoch 23/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4284 - g_loss: 0.4764\n",
      "Epoch 24/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4253 - g_loss: 0.4680\n",
      "Epoch 25/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4222 - g_loss: 0.4598\n",
      "Epoch 26/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4191 - g_loss: 0.4516\n",
      "Epoch 27/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4161 - g_loss: 0.4436\n",
      "Epoch 28/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4132 - g_loss: 0.4357\n",
      "Epoch 29/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4103 - g_loss: 0.4280\n",
      "Epoch 30/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4075 - g_loss: 0.4203\n",
      "Epoch 31/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4047 - g_loss: 0.4127\n",
      "Epoch 32/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.4019 - g_loss: 0.4053\n",
      "Epoch 33/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3993 - g_loss: 0.3979\n",
      "Epoch 34/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3967 - g_loss: 0.3907\n",
      "Epoch 35/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3942 - g_loss: 0.3836\n",
      "Epoch 36/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3917 - g_loss: 0.3766\n",
      "Epoch 37/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3892 - g_loss: 0.3696\n",
      "Epoch 38/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3868 - g_loss: 0.3628\n",
      "Epoch 39/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3845 - g_loss: 0.3561\n",
      "Epoch 40/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3822 - g_loss: 0.3495\n",
      "Epoch 41/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3800 - g_loss: 0.3430\n",
      "Epoch 42/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3778 - g_loss: 0.3367\n",
      "Epoch 43/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3757 - g_loss: 0.3304\n",
      "Epoch 44/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3736 - g_loss: 0.3242\n",
      "Epoch 45/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3716 - g_loss: 0.3181\n",
      "Epoch 46/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3696 - g_loss: 0.3121\n",
      "Epoch 47/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3677 - g_loss: 0.3062\n",
      "Epoch 48/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3658 - g_loss: 0.3004\n",
      "Epoch 49/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3640 - g_loss: 0.2947\n",
      "Epoch 50/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3623 - g_loss: 0.2890\n",
      "Epoch 51/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3606 - g_loss: 0.2835\n",
      "Epoch 52/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3589 - g_loss: 0.2781\n",
      "Epoch 53/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3573 - g_loss: 0.2727\n",
      "Epoch 54/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3557 - g_loss: 0.2675\n",
      "Epoch 55/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - d_loss: 0.3542 - g_loss: 0.2623\n",
      "Epoch 56/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3527 - g_loss: 0.2572\n",
      "Epoch 57/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3513 - g_loss: 0.2522\n",
      "Epoch 58/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - d_loss: 0.3499 - g_loss: 0.2473\n",
      "Epoch 59/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - d_loss: 0.3486 - g_loss: 0.2425\n",
      "Epoch 60/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3473 - g_loss: 0.2378\n",
      "Epoch 61/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - d_loss: 0.3461 - g_loss: 0.2331\n",
      "Epoch 62/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3449 - g_loss: 0.2286\n",
      "Epoch 63/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3438 - g_loss: 0.2241\n",
      "Epoch 64/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - d_loss: 0.3427 - g_loss: 0.2196\n",
      "Epoch 65/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3416 - g_loss: 0.2153\n",
      "Epoch 66/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3406 - g_loss: 0.2110\n",
      "Epoch 67/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - d_loss: 0.3396 - g_loss: 0.2069\n",
      "Epoch 68/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - d_loss: 0.3386 - g_loss: 0.2027\n",
      "Epoch 69/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - d_loss: 0.3377 - g_loss: 0.1987\n",
      "Epoch 70/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - d_loss: 0.3368 - g_loss: 0.1947\n",
      "Epoch 71/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - d_loss: 0.3360 - g_loss: 0.1909\n",
      "Epoch 72/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3352 - g_loss: 0.1870\n",
      "Epoch 73/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - d_loss: 0.3344 - g_loss: 0.1833\n",
      "Epoch 74/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3337 - g_loss: 0.1796\n",
      "Epoch 75/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3330 - g_loss: 0.1760\n",
      "Epoch 76/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3323 - g_loss: 0.1724\n",
      "Epoch 77/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3317 - g_loss: 0.1690\n",
      "Epoch 78/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3311 - g_loss: 0.1655\n",
      "Epoch 79/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3305 - g_loss: 0.1622\n",
      "Epoch 80/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - d_loss: 0.3300 - g_loss: 0.1589\n",
      "Epoch 81/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3295 - g_loss: 0.1557\n",
      "Epoch 82/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3290 - g_loss: 0.1525\n",
      "Epoch 83/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - d_loss: 0.3285 - g_loss: 0.1494\n",
      "Epoch 84/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3281 - g_loss: 0.1463\n",
      "Epoch 85/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3277 - g_loss: 0.1433\n",
      "Epoch 86/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3274 - g_loss: 0.1404\n",
      "Epoch 87/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3271 - g_loss: 0.1375\n",
      "Epoch 88/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3267 - g_loss: 0.1347\n",
      "Epoch 89/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3265 - g_loss: 0.1319\n",
      "Epoch 90/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3262 - g_loss: 0.1292\n",
      "Epoch 91/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3260 - g_loss: 0.1266\n",
      "Epoch 92/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3258 - g_loss: 0.1240\n",
      "Epoch 93/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3256 - g_loss: 0.1214\n",
      "Epoch 94/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3255 - g_loss: 0.1189\n",
      "Epoch 95/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3254 - g_loss: 0.1164\n",
      "Epoch 96/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3253 - g_loss: 0.1140\n",
      "Epoch 97/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3252 - g_loss: 0.1117\n",
      "Epoch 98/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3251 - g_loss: 0.1094\n",
      "Epoch 99/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - d_loss: 0.3251 - g_loss: 0.1073\n",
      "Epoch 100/100\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - d_loss: 0.3251 - g_loss: 0.1058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x258a106b6d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis = build_discriminator(img_dim, num_classes)\n",
    "gen = build_generator(img_dim, num_classes, latent_dim)\n",
    "\n",
    "epochs = 100\n",
    "y_train = tf.keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "\n",
    "gan = GAN(discriminator=dis, generator=gen, latent_dim=latent_dim, num_classes=num_classes)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.RMSprop(learning_rate=0.00001, clipvalue=1.0),\n",
    "    g_optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x100 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_and_compare_image(gan.generator, latent_dim=latent_dim, label=2, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        real_images, real_labels = data  # Unpack the data (images and their labels)\n",
    "\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        # 1. Train the Discriminator:\n",
    "        # --------------------------------\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "\n",
    "        # Generate random labels for the generated images (scalar integers)\n",
    "        random_labels = tf.random.uniform(\n",
    "            shape=(batch_size,), minval=0, maxval=self.num_classes, dtype=tf.int32\n",
    "        )\n",
    "\n",
    "        # Generate fake images conditioned on these random labels\n",
    "        generated_images = self.generator([random_latent_vectors, random_labels])\n",
    "\n",
    "        # Cast real_labels and random_labels to float32\n",
    "        real_labels = tf.reshape(tf.cast(real_labels, tf.float32), [-1])  # Ensure real_labels is 1D\n",
    "        random_labels = tf.reshape(tf.cast(random_labels, tf.float32), [-1])  # Ensure random_labels is 1D\n",
    "\n",
    "        # Check shapes before concatenation\n",
    "        print(\"Shape of generated images:\", generated_images.shape)\n",
    "        print(\"Shape of real images:\", real_images.shape)\n",
    "\n",
    "        # Concatenate real and fake images and their corresponding labels\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        combined_labels = tf.concat([random_labels, real_labels], axis=0)\n",
    "\n",
    "        # Real and fake labels for the discriminator\n",
    "        real_fake_labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)) * 0.9,  # Real labels (0.9 instead of 1 for label smoothing)\n",
    "            tf.zeros((batch_size, 1)) + 0.1],  # Fake labels (0.1 instead of 0 for label smoothing)\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator([combined_images, combined_labels])\n",
    "            d_loss = self.loss_fn(real_fake_labels, predictions)\n",
    "\n",
    "        # Update discriminator weights\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # 2. Train the Generator:\n",
    "        # --------------------------------\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(batch_size, self.latent_dim), seed=self.seed_generator\n",
    "        )\n",
    "\n",
    "        # Generate random labels again (scalar integers)\n",
    "        random_labels = tf.random.uniform(\n",
    "            shape=(batch_size,), minval=0, maxval=self.num_classes, dtype=tf.int32\n",
    "        )\n",
    "\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "        # Train the generator\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator([random_latent_vectors, random_labels])\n",
    "            predictions = self.discriminator([fake_images, tf.cast(random_labels, tf.float32)])\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "\n",
    "        # Update generator weights\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update the loss metrics for both discriminator and generator\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barta\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GAN' object has no attribute 'seed_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 74\u001b[0m\n\u001b[0;32m     66\u001b[0m gan \u001b[38;5;241m=\u001b[39m GAN(discriminator\u001b[38;5;241m=\u001b[39mdis, generator\u001b[38;5;241m=\u001b[39mgen, latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim, num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[0;32m     67\u001b[0m gan\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     68\u001b[0m     d_optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0002\u001b[39m, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m     69\u001b[0m     g_optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0002\u001b[39m, beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m     70\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m gan\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39mepochs)\n",
      "File \u001b[1;32mc:\\Users\\barta\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[29], line 31\u001b[0m, in \u001b[0;36mGAN.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     24\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(real_images)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 1. Train the Discriminator:\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# --------------------------------\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Sample random points in the latent space\u001b[39;00m\n\u001b[0;32m     30\u001b[0m random_latent_vectors \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\n\u001b[1;32m---> 31\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim), seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed_generator\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Generate random labels for the generated images (scalar integers)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m random_labels \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m     36\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(batch_size,), minval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, maxval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32\n\u001b[0;32m     37\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GAN' object has no attribute 'seed_generator'"
     ]
    }
   ],
   "source": [
    "img_dim = 28\n",
    "num_classes = 26\n",
    "latent_dim = 32\n",
    "\n",
    "def build_discriminator(img_dim, num_classes):\n",
    "    image_input = layers.Input(shape=(img_dim, img_dim, 1))  # Grayscale image input\n",
    "    label_input = layers.Input(shape=(1,))\n",
    "    \n",
    "    # Expand the label to match the image dimensions\n",
    "    label_embedding = layers.Embedding(input_dim=num_classes, output_dim=img_dim*img_dim)(label_input)\n",
    "    label_embedding = layers.Reshape((img_dim, img_dim, 1))(label_embedding)\n",
    "    \n",
    "    # Concatenate label and image\n",
    "    concat = layers.Concatenate()([image_input, label_embedding])\n",
    "    \n",
    "    # Convolutional layers\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(concat)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    real_or_fake = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    return tf.keras.Model([image_input, label_input], real_or_fake)\n",
    "\n",
    "# Generator with embedded labels and batch normalization\n",
    "def build_generator(img_dim, num_classes, latent_dim):\n",
    "    latent_input = layers.Input(shape=(latent_dim,))\n",
    "    label_input = layers.Input(shape=(1,))\n",
    "    \n",
    "    # Embed the label and concatenate with latent input\n",
    "    label_embedding = layers.Embedding(num_classes, latent_dim)(label_input)\n",
    "    label_embedding = layers.Flatten()(label_embedding)\n",
    "    concat = layers.Concatenate()([latent_input, label_embedding])\n",
    "    \n",
    "    # Fully connected layers\n",
    "    x = layers.Dense(128 * 7 * 7, activation=\"relu\")(concat)\n",
    "    x = layers.Reshape((7, 7, 128))(x)\n",
    "    \n",
    "    # Upsampling layers\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\")(x)  # 7x7 -> 14x14\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\")(x)  # 14x14 -> 28x28\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    generated_image = layers.Conv2DTranspose(1, kernel_size=7, activation=\"tanh\", padding=\"same\")(x)  # Final 28x28 output\n",
    "    \n",
    "    return tf.keras.Model([latent_input, label_input], generated_image)\n",
    "\n",
    "dis = build_discriminator(img_dim, num_classes)\n",
    "gen = build_generator(img_dim, num_classes, latent_dim)\n",
    "\n",
    "epochs = 100\n",
    "y_train = tf.keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "\n",
    "gan = GAN(discriminator=dis, generator=gen, latent_dim=latent_dim, num_classes=num_classes)\n",
    "gan.compile(\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    ")\n",
    "\n",
    "\n",
    "gan.fit(X_train, y_train, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
